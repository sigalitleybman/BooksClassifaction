{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba0c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Perceptron \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,confusion_matrix\n",
    "from sklearn import metrics, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e529d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"books_without_outliers.csv\", index_col = [0])\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4fe3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_genre</th>\n",
       "      <th>book_rate</th>\n",
       "      <th>successfull_book</th>\n",
       "      <th>paperback</th>\n",
       "      <th>hardback</th>\n",
       "      <th>author</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>book_length_mm</th>\n",
       "      <th>book_width_mm</th>\n",
       "      <th>book_depth_mm</th>\n",
       "      <th>book_weight_grams</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publication_city</th>\n",
       "      <th>publication_country</th>\n",
       "      <th>language</th>\n",
       "      <th>bestsellers_rank</th>\n",
       "      <th>price_nis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225</td>\n",
       "      <td>6225</td>\n",
       "      <td>6225</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "      <td>6225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>682</td>\n",
       "      <td>307</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander McCall Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penguin Books Ltd</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>407</td>\n",
       "      <td>3087</td>\n",
       "      <td>3511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.964819</td>\n",
       "      <td>4.062991</td>\n",
       "      <td>0.620080</td>\n",
       "      <td>0.610120</td>\n",
       "      <td>0.389880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.126104</td>\n",
       "      <td>210.489333</td>\n",
       "      <td>143.827831</td>\n",
       "      <td>22.989595</td>\n",
       "      <td>383.531762</td>\n",
       "      <td>12.937189</td>\n",
       "      <td>6.606265</td>\n",
       "      <td>2014.114699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.013173</td>\n",
       "      <td>57783.771727</td>\n",
       "      <td>69.429277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.847013</td>\n",
       "      <td>0.260948</td>\n",
       "      <td>0.485406</td>\n",
       "      <td>0.487762</td>\n",
       "      <td>0.487762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.711780</td>\n",
       "      <td>22.319650</td>\n",
       "      <td>21.295494</td>\n",
       "      <td>8.160141</td>\n",
       "      <td>197.401192</td>\n",
       "      <td>9.715791</td>\n",
       "      <td>3.298895</td>\n",
       "      <td>6.016768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203961</td>\n",
       "      <td>55669.107233</td>\n",
       "      <td>21.075414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>17.780000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12153.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42682.000000</td>\n",
       "      <td>66.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>83218.000000</td>\n",
       "      <td>81.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1115.840000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>259033.000000</td>\n",
       "      <td>151.330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         book_genre    book_rate  successfull_book    paperback     hardback  \\\n",
       "count   6225.000000  6225.000000       6225.000000  6225.000000  6225.000000   \n",
       "unique          NaN          NaN               NaN          NaN          NaN   \n",
       "top             NaN          NaN               NaN          NaN          NaN   \n",
       "freq            NaN          NaN               NaN          NaN          NaN   \n",
       "mean       1.964819     4.062991          0.620080     0.610120     0.389880   \n",
       "std        0.847013     0.260948          0.485406     0.487762     0.487762   \n",
       "min        1.000000     3.310000          0.000000     0.000000     0.000000   \n",
       "25%        1.000000     3.890000          0.000000     0.000000     0.000000   \n",
       "50%        2.000000     4.080000          1.000000     1.000000     0.000000   \n",
       "75%        3.000000     4.250000          1.000000     1.000000     1.000000   \n",
       "max        3.000000     4.860000          1.000000     1.000000     1.000000   \n",
       "\n",
       "                        author  number_of_pages  book_length_mm  \\\n",
       "count                     6225      6225.000000     6225.000000   \n",
       "unique                    3775              NaN             NaN   \n",
       "top     Alexander McCall Smith              NaN             NaN   \n",
       "freq                        33              NaN             NaN   \n",
       "mean                       NaN       300.126104      210.489333   \n",
       "std                        NaN       115.711780       22.319650   \n",
       "min                        NaN         1.000000      144.000000   \n",
       "25%                        NaN       224.000000      198.000000   \n",
       "50%                        NaN       288.000000      206.000000   \n",
       "75%                        NaN       368.000000      229.000000   \n",
       "max                        NaN       624.000000      285.000000   \n",
       "\n",
       "        book_width_mm  book_depth_mm  book_weight_grams  publication_day  \\\n",
       "count     6225.000000    6225.000000        6225.000000      6225.000000   \n",
       "unique            NaN            NaN                NaN              NaN   \n",
       "top               NaN            NaN                NaN              NaN   \n",
       "freq              NaN            NaN                NaN              NaN   \n",
       "mean       143.827831      22.989595         383.531762        12.937189   \n",
       "std         21.295494       8.160141         197.401192         9.715791   \n",
       "min         89.000000       1.000000           1.000000         1.000000   \n",
       "25%        129.000000      17.780000         241.000000         4.000000   \n",
       "50%        139.000000      22.860000         336.000000        11.000000   \n",
       "75%        155.000000      28.000000         499.000000        21.000000   \n",
       "max        211.000000      48.000000        1115.840000        31.000000   \n",
       "\n",
       "        publication_month  publication_year          publisher  \\\n",
       "count         6225.000000       6225.000000               6225   \n",
       "unique                NaN               NaN                682   \n",
       "top                   NaN               NaN  Penguin Books Ltd   \n",
       "freq                  NaN               NaN                407   \n",
       "mean             6.606265       2014.114699                NaN   \n",
       "std              3.298895          6.016768                NaN   \n",
       "min              1.000000       1997.000000                NaN   \n",
       "25%              4.000000       2011.000000                NaN   \n",
       "50%              7.000000       2015.000000                NaN   \n",
       "75%              9.000000       2019.000000                NaN   \n",
       "max             12.000000       2022.000000                NaN   \n",
       "\n",
       "       publication_city publication_country     language  bestsellers_rank  \\\n",
       "count              6225                6225  6225.000000       6225.000000   \n",
       "unique              307                  60          NaN               NaN   \n",
       "top              London      United Kingdom          NaN               NaN   \n",
       "freq               3087                3511          NaN               NaN   \n",
       "mean                NaN                 NaN     1.013173      57783.771727   \n",
       "std                 NaN                 NaN     0.203961      55669.107233   \n",
       "min                 NaN                 NaN     1.000000          1.000000   \n",
       "25%                 NaN                 NaN     1.000000      12153.000000   \n",
       "50%                 NaN                 NaN     1.000000      42682.000000   \n",
       "75%                 NaN                 NaN     1.000000      83218.000000   \n",
       "max                 NaN                 NaN     6.000000     259033.000000   \n",
       "\n",
       "          price_nis  \n",
       "count   6225.000000  \n",
       "unique          NaN  \n",
       "top             NaN  \n",
       "freq            NaN  \n",
       "mean      69.429277  \n",
       "std       21.075414  \n",
       "min       19.590000  \n",
       "25%       53.000000  \n",
       "50%       66.060000  \n",
       "75%       81.800000  \n",
       "max      151.330000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.describe(include ='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77cfdbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_genre               int64\n",
       "book_rate              float64\n",
       "successfull_book         int64\n",
       "paperback                int64\n",
       "hardback                 int64\n",
       "author                  object\n",
       "number_of_pages        float64\n",
       "book_length_mm         float64\n",
       "book_width_mm          float64\n",
       "book_depth_mm          float64\n",
       "book_weight_grams      float64\n",
       "publication_day          int64\n",
       "publication_month        int64\n",
       "publication_year         int64\n",
       "publisher               object\n",
       "publication_city        object\n",
       "publication_country     object\n",
       "language                 int64\n",
       "bestsellers_rank         int64\n",
       "price_nis              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467328d",
   "metadata": {},
   "source": [
    "## Let's change all the objects columns to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e589f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = df_copy.author.unique()\n",
    "replace_author = {authors[i] : i + 1 for i in range(0,len(authors))}\n",
    "df_copy.replace(replace_author, inplace = True)\n",
    "\n",
    "publishers = df_copy.publisher.unique()\n",
    "replace_publisher = {publishers[i] : i + 1 for i in range(0,len(publishers))}\n",
    "df_copy.replace(replace_publisher, inplace = True)\n",
    "\n",
    "cities = df_copy.publication_city.unique()\n",
    "replace_city = {cities[i] : i + 1 for i in range(0,len(cities))}\n",
    "df_copy.replace(replace_city, inplace = True)\n",
    "\n",
    "countries = df_copy.publication_country.unique()\n",
    "replace_country = {countries[i] : i + 1 for i in range(0,len(countries))}\n",
    "df_copy.replace(replace_country, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd93348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_genre               int64\n",
       "book_rate              float64\n",
       "successfull_book         int64\n",
       "paperback                int64\n",
       "hardback                 int64\n",
       "author                   int64\n",
       "number_of_pages        float64\n",
       "book_length_mm         float64\n",
       "book_width_mm          float64\n",
       "book_depth_mm          float64\n",
       "book_weight_grams      float64\n",
       "publication_day          int64\n",
       "publication_month        int64\n",
       "publication_year         int64\n",
       "publisher                int64\n",
       "publication_city         int64\n",
       "publication_country      int64\n",
       "language                 int64\n",
       "bestsellers_rank         int64\n",
       "price_nis              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4434aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57886947",
   "metadata": {},
   "source": [
    "### let's see the correlation between the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c159b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_genre</th>\n",
       "      <th>book_rate</th>\n",
       "      <th>successfull_book</th>\n",
       "      <th>paperback</th>\n",
       "      <th>hardback</th>\n",
       "      <th>author</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>book_length_mm</th>\n",
       "      <th>book_width_mm</th>\n",
       "      <th>book_depth_mm</th>\n",
       "      <th>book_weight_grams</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publication_city</th>\n",
       "      <th>publication_country</th>\n",
       "      <th>language</th>\n",
       "      <th>bestsellers_rank</th>\n",
       "      <th>price_nis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>book_genre</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123069</td>\n",
       "      <td>0.184370</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>0.900108</td>\n",
       "      <td>-0.250065</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>-0.158696</td>\n",
       "      <td>0.049225</td>\n",
       "      <td>0.022541</td>\n",
       "      <td>0.022203</td>\n",
       "      <td>-0.072224</td>\n",
       "      <td>0.476343</td>\n",
       "      <td>0.367441</td>\n",
       "      <td>0.188223</td>\n",
       "      <td>-0.047673</td>\n",
       "      <td>0.105023</td>\n",
       "      <td>0.143697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_rate</th>\n",
       "      <td>0.123069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.432390</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>-0.014124</td>\n",
       "      <td>0.091607</td>\n",
       "      <td>0.045651</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>0.106285</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.025287</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.102384</td>\n",
       "      <td>0.109450</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.022006</td>\n",
       "      <td>-0.054903</td>\n",
       "      <td>0.122615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>successfull_book</th>\n",
       "      <td>0.184370</td>\n",
       "      <td>0.432390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>-0.027100</td>\n",
       "      <td>0.152432</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>0.065611</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.126941</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>-0.008843</td>\n",
       "      <td>0.148260</td>\n",
       "      <td>0.156242</td>\n",
       "      <td>0.107612</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>-0.069608</td>\n",
       "      <td>0.138247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperback</th>\n",
       "      <td>0.040296</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.147666</td>\n",
       "      <td>0.143054</td>\n",
       "      <td>-0.130339</td>\n",
       "      <td>-0.095507</td>\n",
       "      <td>-0.274729</td>\n",
       "      <td>-0.443966</td>\n",
       "      <td>-0.043711</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.372477</td>\n",
       "      <td>-0.052698</td>\n",
       "      <td>0.064383</td>\n",
       "      <td>0.035245</td>\n",
       "      <td>-0.049114</td>\n",
       "      <td>-0.339458</td>\n",
       "      <td>-0.449981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardback</th>\n",
       "      <td>-0.040296</td>\n",
       "      <td>-0.014124</td>\n",
       "      <td>-0.027100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147666</td>\n",
       "      <td>-0.143054</td>\n",
       "      <td>0.130339</td>\n",
       "      <td>0.095507</td>\n",
       "      <td>0.274729</td>\n",
       "      <td>0.443966</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>0.372477</td>\n",
       "      <td>0.052698</td>\n",
       "      <td>-0.064383</td>\n",
       "      <td>-0.035245</td>\n",
       "      <td>0.049114</td>\n",
       "      <td>0.339458</td>\n",
       "      <td>0.449981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>0.900108</td>\n",
       "      <td>0.091607</td>\n",
       "      <td>0.152432</td>\n",
       "      <td>-0.147666</td>\n",
       "      <td>0.147666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.283235</td>\n",
       "      <td>0.080378</td>\n",
       "      <td>0.191652</td>\n",
       "      <td>-0.113691</td>\n",
       "      <td>0.138435</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.505209</td>\n",
       "      <td>0.359809</td>\n",
       "      <td>0.177941</td>\n",
       "      <td>-0.027006</td>\n",
       "      <td>0.243954</td>\n",
       "      <td>0.226568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_pages</th>\n",
       "      <td>-0.250065</td>\n",
       "      <td>0.045651</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>0.143054</td>\n",
       "      <td>-0.143054</td>\n",
       "      <td>-0.283235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020396</td>\n",
       "      <td>-0.111078</td>\n",
       "      <td>0.555495</td>\n",
       "      <td>0.314137</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>-0.014890</td>\n",
       "      <td>0.054048</td>\n",
       "      <td>-0.239628</td>\n",
       "      <td>-0.155232</td>\n",
       "      <td>-0.076938</td>\n",
       "      <td>-0.084436</td>\n",
       "      <td>-0.115735</td>\n",
       "      <td>0.134754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_length_mm</th>\n",
       "      <td>0.035692</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>-0.130339</td>\n",
       "      <td>0.130339</td>\n",
       "      <td>0.080378</td>\n",
       "      <td>0.020396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318687</td>\n",
       "      <td>0.109018</td>\n",
       "      <td>0.381148</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>0.072841</td>\n",
       "      <td>0.105936</td>\n",
       "      <td>0.109839</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>-0.087424</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>0.404064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_width_mm</th>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.065611</td>\n",
       "      <td>-0.095507</td>\n",
       "      <td>0.095507</td>\n",
       "      <td>0.191652</td>\n",
       "      <td>-0.111078</td>\n",
       "      <td>0.318687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018351</td>\n",
       "      <td>0.349025</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.038891</td>\n",
       "      <td>0.157280</td>\n",
       "      <td>0.138557</td>\n",
       "      <td>0.089117</td>\n",
       "      <td>-0.025992</td>\n",
       "      <td>0.093769</td>\n",
       "      <td>0.286508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_depth_mm</th>\n",
       "      <td>-0.158696</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>-0.274729</td>\n",
       "      <td>0.274729</td>\n",
       "      <td>-0.113691</td>\n",
       "      <td>0.555495</td>\n",
       "      <td>0.109018</td>\n",
       "      <td>-0.018351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419955</td>\n",
       "      <td>0.021036</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.225575</td>\n",
       "      <td>-0.116787</td>\n",
       "      <td>-0.121890</td>\n",
       "      <td>-0.052711</td>\n",
       "      <td>-0.037457</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>0.299890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_weight_grams</th>\n",
       "      <td>0.049225</td>\n",
       "      <td>0.106285</td>\n",
       "      <td>0.126941</td>\n",
       "      <td>-0.443966</td>\n",
       "      <td>0.443966</td>\n",
       "      <td>0.138435</td>\n",
       "      <td>0.314137</td>\n",
       "      <td>0.381148</td>\n",
       "      <td>0.349025</td>\n",
       "      <td>0.419955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048958</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.253794</td>\n",
       "      <td>0.147257</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.041950</td>\n",
       "      <td>-0.032003</td>\n",
       "      <td>0.184975</td>\n",
       "      <td>0.724746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_day</th>\n",
       "      <td>0.022541</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-0.043711</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.021036</td>\n",
       "      <td>0.048958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.118879</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>-0.017717</td>\n",
       "      <td>-0.018491</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>0.052361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_month</th>\n",
       "      <td>0.022203</td>\n",
       "      <td>0.025287</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>-0.014890</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020369</td>\n",
       "      <td>0.036467</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>-0.014326</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.060403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_year</th>\n",
       "      <td>-0.072224</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>-0.008843</td>\n",
       "      <td>-0.372477</td>\n",
       "      <td>0.372477</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.054048</td>\n",
       "      <td>0.072841</td>\n",
       "      <td>0.038891</td>\n",
       "      <td>0.225575</td>\n",
       "      <td>0.253794</td>\n",
       "      <td>0.118879</td>\n",
       "      <td>-0.020369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054692</td>\n",
       "      <td>-0.136349</td>\n",
       "      <td>-0.080055</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>0.038552</td>\n",
       "      <td>0.157843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <td>0.476343</td>\n",
       "      <td>0.102384</td>\n",
       "      <td>0.148260</td>\n",
       "      <td>-0.052698</td>\n",
       "      <td>0.052698</td>\n",
       "      <td>0.505209</td>\n",
       "      <td>-0.239628</td>\n",
       "      <td>0.105936</td>\n",
       "      <td>0.157280</td>\n",
       "      <td>-0.116787</td>\n",
       "      <td>0.147257</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>0.036467</td>\n",
       "      <td>-0.054692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692783</td>\n",
       "      <td>0.342667</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.106747</td>\n",
       "      <td>0.261003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_city</th>\n",
       "      <td>0.367441</td>\n",
       "      <td>0.109450</td>\n",
       "      <td>0.156242</td>\n",
       "      <td>0.064383</td>\n",
       "      <td>-0.064383</td>\n",
       "      <td>0.359809</td>\n",
       "      <td>-0.155232</td>\n",
       "      <td>0.109839</td>\n",
       "      <td>0.138557</td>\n",
       "      <td>-0.121890</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>-0.136349</td>\n",
       "      <td>0.692783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414048</td>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.045407</td>\n",
       "      <td>0.202795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_country</th>\n",
       "      <td>0.188223</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.107612</td>\n",
       "      <td>0.035245</td>\n",
       "      <td>-0.035245</td>\n",
       "      <td>0.177941</td>\n",
       "      <td>-0.076938</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.089117</td>\n",
       "      <td>-0.052711</td>\n",
       "      <td>0.041950</td>\n",
       "      <td>-0.017717</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>-0.080055</td>\n",
       "      <td>0.342667</td>\n",
       "      <td>0.414048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093641</td>\n",
       "      <td>0.047967</td>\n",
       "      <td>0.131883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>-0.047673</td>\n",
       "      <td>0.022006</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>-0.049114</td>\n",
       "      <td>0.049114</td>\n",
       "      <td>-0.027006</td>\n",
       "      <td>-0.084436</td>\n",
       "      <td>-0.087424</td>\n",
       "      <td>-0.025992</td>\n",
       "      <td>-0.037457</td>\n",
       "      <td>-0.032003</td>\n",
       "      <td>-0.018491</td>\n",
       "      <td>-0.014326</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.093641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>-0.027468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestsellers_rank</th>\n",
       "      <td>0.105023</td>\n",
       "      <td>-0.054903</td>\n",
       "      <td>-0.069608</td>\n",
       "      <td>-0.339458</td>\n",
       "      <td>0.339458</td>\n",
       "      <td>0.243954</td>\n",
       "      <td>-0.115735</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>0.093769</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>0.184975</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.038552</td>\n",
       "      <td>0.106747</td>\n",
       "      <td>0.045407</td>\n",
       "      <td>0.047967</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_nis</th>\n",
       "      <td>0.143697</td>\n",
       "      <td>0.122615</td>\n",
       "      <td>0.138247</td>\n",
       "      <td>-0.449981</td>\n",
       "      <td>0.449981</td>\n",
       "      <td>0.226568</td>\n",
       "      <td>0.134754</td>\n",
       "      <td>0.404064</td>\n",
       "      <td>0.286508</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.724746</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.157843</td>\n",
       "      <td>0.261003</td>\n",
       "      <td>0.202795</td>\n",
       "      <td>0.131883</td>\n",
       "      <td>-0.027468</td>\n",
       "      <td>0.276939</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     book_genre  book_rate  successfull_book  paperback  \\\n",
       "book_genre             1.000000   0.123069          0.184370   0.040296   \n",
       "book_rate              0.123069   1.000000          0.432390   0.014124   \n",
       "successfull_book       0.184370   0.432390          1.000000   0.027100   \n",
       "paperback              0.040296   0.014124          0.027100   1.000000   \n",
       "hardback              -0.040296  -0.014124         -0.027100  -1.000000   \n",
       "author                 0.900108   0.091607          0.152432  -0.147666   \n",
       "number_of_pages       -0.250065   0.045651          0.038417   0.143054   \n",
       "book_length_mm         0.035692   0.055651          0.042964  -0.130339   \n",
       "book_width_mm          0.140699   0.035916          0.065611  -0.095507   \n",
       "book_depth_mm         -0.158696   0.044212          0.023822  -0.274729   \n",
       "book_weight_grams      0.049225   0.106285          0.126941  -0.443966   \n",
       "publication_day        0.022541   0.008357          0.020582  -0.043711   \n",
       "publication_month      0.022203   0.025287          0.014607  -0.062527   \n",
       "publication_year      -0.072224   0.002992         -0.008843  -0.372477   \n",
       "publisher              0.476343   0.102384          0.148260  -0.052698   \n",
       "publication_city       0.367441   0.109450          0.156242   0.064383   \n",
       "publication_country    0.188223   0.046145          0.107612   0.035245   \n",
       "language              -0.047673   0.022006          0.034188  -0.049114   \n",
       "bestsellers_rank       0.105023  -0.054903         -0.069608  -0.339458   \n",
       "price_nis              0.143697   0.122615          0.138247  -0.449981   \n",
       "\n",
       "                     hardback    author  number_of_pages  book_length_mm  \\\n",
       "book_genre          -0.040296  0.900108        -0.250065        0.035692   \n",
       "book_rate           -0.014124  0.091607         0.045651        0.055651   \n",
       "successfull_book    -0.027100  0.152432         0.038417        0.042964   \n",
       "paperback           -1.000000 -0.147666         0.143054       -0.130339   \n",
       "hardback             1.000000  0.147666        -0.143054        0.130339   \n",
       "author               0.147666  1.000000        -0.283235        0.080378   \n",
       "number_of_pages     -0.143054 -0.283235         1.000000        0.020396   \n",
       "book_length_mm       0.130339  0.080378         0.020396        1.000000   \n",
       "book_width_mm        0.095507  0.191652        -0.111078        0.318687   \n",
       "book_depth_mm        0.274729 -0.113691         0.555495        0.109018   \n",
       "book_weight_grams    0.443966  0.138435         0.314137        0.381148   \n",
       "publication_day      0.043711  0.029539         0.007180        0.018769   \n",
       "publication_month    0.062527  0.020900        -0.014890        0.012910   \n",
       "publication_year     0.372477  0.009573         0.054048        0.072841   \n",
       "publisher            0.052698  0.505209        -0.239628        0.105936   \n",
       "publication_city    -0.064383  0.359809        -0.155232        0.109839   \n",
       "publication_country -0.035245  0.177941        -0.076938        0.069514   \n",
       "language             0.049114 -0.027006        -0.084436       -0.087424   \n",
       "bestsellers_rank     0.339458  0.243954        -0.115735        0.097658   \n",
       "price_nis            0.449981  0.226568         0.134754        0.404064   \n",
       "\n",
       "                     book_width_mm  book_depth_mm  book_weight_grams  \\\n",
       "book_genre                0.140699      -0.158696           0.049225   \n",
       "book_rate                 0.035916       0.044212           0.106285   \n",
       "successfull_book          0.065611       0.023822           0.126941   \n",
       "paperback                -0.095507      -0.274729          -0.443966   \n",
       "hardback                  0.095507       0.274729           0.443966   \n",
       "author                    0.191652      -0.113691           0.138435   \n",
       "number_of_pages          -0.111078       0.555495           0.314137   \n",
       "book_length_mm            0.318687       0.109018           0.381148   \n",
       "book_width_mm             1.000000      -0.018351           0.349025   \n",
       "book_depth_mm            -0.018351       1.000000           0.419955   \n",
       "book_weight_grams         0.349025       0.419955           1.000000   \n",
       "publication_day           0.000790       0.021036           0.048958   \n",
       "publication_month         0.026716       0.026757           0.063080   \n",
       "publication_year          0.038891       0.225575           0.253794   \n",
       "publisher                 0.157280      -0.116787           0.147257   \n",
       "publication_city          0.138557      -0.121890           0.070430   \n",
       "publication_country       0.089117      -0.052711           0.041950   \n",
       "language                 -0.025992      -0.037457          -0.032003   \n",
       "bestsellers_rank          0.093769       0.031421           0.184975   \n",
       "price_nis                 0.286508       0.299890           0.724746   \n",
       "\n",
       "                     publication_day  publication_month  publication_year  \\\n",
       "book_genre                  0.022541           0.022203         -0.072224   \n",
       "book_rate                   0.008357           0.025287          0.002992   \n",
       "successfull_book            0.020582           0.014607         -0.008843   \n",
       "paperback                  -0.043711          -0.062527         -0.372477   \n",
       "hardback                    0.043711           0.062527          0.372477   \n",
       "author                      0.029539           0.020900          0.009573   \n",
       "number_of_pages             0.007180          -0.014890          0.054048   \n",
       "book_length_mm              0.018769           0.012910          0.072841   \n",
       "book_width_mm               0.000790           0.026716          0.038891   \n",
       "book_depth_mm               0.021036           0.026757          0.225575   \n",
       "book_weight_grams           0.048958           0.063080          0.253794   \n",
       "publication_day             1.000000           0.001846          0.118879   \n",
       "publication_month           0.001846           1.000000         -0.020369   \n",
       "publication_year            0.118879          -0.020369          1.000000   \n",
       "publisher                  -0.000543           0.036467         -0.054692   \n",
       "publication_city           -0.002014           0.029455         -0.136349   \n",
       "publication_country        -0.017717           0.006082         -0.080055   \n",
       "language                   -0.018491          -0.014326         -0.014133   \n",
       "bestsellers_rank            0.028841           0.010058          0.038552   \n",
       "price_nis                   0.052361           0.060403          0.157843   \n",
       "\n",
       "                     publisher  publication_city  publication_country  \\\n",
       "book_genre            0.476343          0.367441             0.188223   \n",
       "book_rate             0.102384          0.109450             0.046145   \n",
       "successfull_book      0.148260          0.156242             0.107612   \n",
       "paperback            -0.052698          0.064383             0.035245   \n",
       "hardback              0.052698         -0.064383            -0.035245   \n",
       "author                0.505209          0.359809             0.177941   \n",
       "number_of_pages      -0.239628         -0.155232            -0.076938   \n",
       "book_length_mm        0.105936          0.109839             0.069514   \n",
       "book_width_mm         0.157280          0.138557             0.089117   \n",
       "book_depth_mm        -0.116787         -0.121890            -0.052711   \n",
       "book_weight_grams     0.147257          0.070430             0.041950   \n",
       "publication_day      -0.000543         -0.002014            -0.017717   \n",
       "publication_month     0.036467          0.029455             0.006082   \n",
       "publication_year     -0.054692         -0.136349            -0.080055   \n",
       "publisher             1.000000          0.692783             0.342667   \n",
       "publication_city      0.692783          1.000000             0.414048   \n",
       "publication_country   0.342667          0.414048             1.000000   \n",
       "language              0.016428          0.021348             0.093641   \n",
       "bestsellers_rank      0.106747          0.045407             0.047967   \n",
       "price_nis             0.261003          0.202795             0.131883   \n",
       "\n",
       "                     language  bestsellers_rank  price_nis  \n",
       "book_genre          -0.047673          0.105023   0.143697  \n",
       "book_rate            0.022006         -0.054903   0.122615  \n",
       "successfull_book     0.034188         -0.069608   0.138247  \n",
       "paperback           -0.049114         -0.339458  -0.449981  \n",
       "hardback             0.049114          0.339458   0.449981  \n",
       "author              -0.027006          0.243954   0.226568  \n",
       "number_of_pages     -0.084436         -0.115735   0.134754  \n",
       "book_length_mm      -0.087424          0.097658   0.404064  \n",
       "book_width_mm       -0.025992          0.093769   0.286508  \n",
       "book_depth_mm       -0.037457          0.031421   0.299890  \n",
       "book_weight_grams   -0.032003          0.184975   0.724746  \n",
       "publication_day     -0.018491          0.028841   0.052361  \n",
       "publication_month   -0.014326          0.010058   0.060403  \n",
       "publication_year    -0.014133          0.038552   0.157843  \n",
       "publisher            0.016428          0.106747   0.261003  \n",
       "publication_city     0.021348          0.045407   0.202795  \n",
       "publication_country  0.093641          0.047967   0.131883  \n",
       "language             1.000000          0.007519  -0.027468  \n",
       "bestsellers_rank     0.007519          1.000000   0.276939  \n",
       "price_nis           -0.027468          0.276939   1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf536d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2346\n",
       "3    2127\n",
       "2    1752\n",
       "Name: book_genre, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.book_genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b88f7d",
   "metadata": {},
   "source": [
    "### Building 3 data frames for each of the categories and concat them to one final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caba0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows = 1752\n",
    "\n",
    "# here we took samples of fiction category\n",
    "sample_fiction_df = df_copy[df_copy[\"book_genre\"] == 1].sample(n = number_of_rows, random_state = 1)\n",
    "\n",
    "\n",
    "sample_sport_df = df_copy[df_copy[\"book_genre\"] == 2].head(number_of_rows)\n",
    "\n",
    "# here we took samples of mbs category\n",
    "sample_mbs_df =  df_copy[df_copy[\"book_genre\"] == 3].sample(n = number_of_rows, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52e2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [sample_fiction_df, sample_sport_df, sample_mbs_df]\n",
    "\n",
    "df_samples = pd.concat(data_frames)"
   ]
  },
  {
   "attachments": {
    "Screenshot%201%28137%29.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7e5c1e91",
   "metadata": {},
   "source": [
    "### We had to make a multiclass classification because of our reaserch question\n",
    "\n",
    "#### Macro average - when you have balanced categories.<br>\n",
    "\n",
    "![Screenshot%201%28137%29.png](attachment:Screenshot%201%28137%29.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7a0145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix of RandomForest :\n",
      "[[555   1   1]\n",
      " [  5 480   7]\n",
      " [ 20  20 488]]\n",
      "\n",
      "confusion_matrix of DecisionTree :\n",
      "[[536  13   8]\n",
      " [  4 466  22]\n",
      " [ 19  19 490]]\n",
      "\n",
      "confusion_matrix of KNN :\n",
      "[[501  56   0]\n",
      " [ 27 439  26]\n",
      " [ 23  57 448]]\n",
      "\n",
      "confusion_matrix of Naive Bayes :\n",
      "[[395 138  24]\n",
      " [  6 309 177]\n",
      " [ 15 106 407]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_e75b9_row0_col0,#T_e75b9_row0_col2,#T_e75b9_row0_col3,#T_e75b9_row0_col4,#T_e75b9_row1_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_e75b9_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >accuracy_on_test</th>        <th class=\"col_heading level0 col1\" >accuracy_on_train</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >f1</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e75b9_level0_row0\" class=\"row_heading level0 row0\" >RandomForest</th>\n",
       "                        <td id=\"T_e75b9_row0_col0\" class=\"data row0 col0\" >0.966</td>\n",
       "                        <td id=\"T_e75b9_row0_col1\" class=\"data row0 col1\" >0.994</td>\n",
       "                        <td id=\"T_e75b9_row0_col2\" class=\"data row0 col2\" >0.966</td>\n",
       "                        <td id=\"T_e75b9_row0_col3\" class=\"data row0 col3\" >0.965</td>\n",
       "                        <td id=\"T_e75b9_row0_col4\" class=\"data row0 col4\" >0.965</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e75b9_level0_row1\" class=\"row_heading level0 row1\" >DecisionTree</th>\n",
       "                        <td id=\"T_e75b9_row1_col0\" class=\"data row1 col0\" >0.946</td>\n",
       "                        <td id=\"T_e75b9_row1_col1\" class=\"data row1 col1\" >0.995</td>\n",
       "                        <td id=\"T_e75b9_row1_col2\" class=\"data row1 col2\" >0.946</td>\n",
       "                        <td id=\"T_e75b9_row1_col3\" class=\"data row1 col3\" >0.946</td>\n",
       "                        <td id=\"T_e75b9_row1_col4\" class=\"data row1 col4\" >0.946</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e75b9_level0_row2\" class=\"row_heading level0 row2\" >KNN</th>\n",
       "                        <td id=\"T_e75b9_row2_col0\" class=\"data row2 col0\" >0.880</td>\n",
       "                        <td id=\"T_e75b9_row2_col1\" class=\"data row2 col1\" >0.926</td>\n",
       "                        <td id=\"T_e75b9_row2_col2\" class=\"data row2 col2\" >0.883</td>\n",
       "                        <td id=\"T_e75b9_row2_col3\" class=\"data row2 col3\" >0.880</td>\n",
       "                        <td id=\"T_e75b9_row2_col4\" class=\"data row2 col4\" >0.880</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e75b9_level0_row3\" class=\"row_heading level0 row3\" >Naive Bayes</th>\n",
       "                        <td id=\"T_e75b9_row3_col0\" class=\"data row3 col0\" >0.705</td>\n",
       "                        <td id=\"T_e75b9_row3_col1\" class=\"data row3 col1\" >0.692</td>\n",
       "                        <td id=\"T_e75b9_row3_col2\" class=\"data row3 col2\" >0.726</td>\n",
       "                        <td id=\"T_e75b9_row3_col3\" class=\"data row3 col3\" >0.703</td>\n",
       "                        <td id=\"T_e75b9_row3_col4\" class=\"data row3 col4\" >0.707</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2706aa34fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building the X and y df's\n",
    "X = df_samples.drop('book_genre', axis = 1)\n",
    "y = df_samples['book_genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "\n",
    "\"\"\" we wanted to test couple models and see the differences between them \"\"\"\n",
    "\n",
    "ml_models = {\n",
    "    'RandomForest'      : RandomForestClassifier(),   \n",
    "    'DecisionTree'      : DecisionTreeClassifier(),   \n",
    "    'KNN'               : KNeighborsClassifier(), \n",
    "    'Naive Bayes'       : MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), \n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame([])\n",
    "\n",
    "\"\"\" for loop to build the different models to predict and train them \"\"\"\n",
    "for model_name in ml_models:\n",
    "    \n",
    "    metrics = {}\n",
    "\n",
    "    clf_model = ml_models[model_name].fit(X_train, y_train)\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "    y_pred_train = clf_model.predict(X_train)\n",
    "    \n",
    "    \n",
    "    metrics['accuracy_on_test'] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    metrics['accuracy_on_train'] = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    metrics['precision'] = precision_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    metrics['recall'] = recall_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    metrics['f1'] = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    df_metrics = pd.concat([df_metrics,pd.DataFrame(metrics, index=[model_name]).T],axis=1)\n",
    "    \n",
    "    print(\"confusion_matrix of\", model_name, \":\")\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "df_metrics.T.style.highlight_max(color='lightgreen').set_precision(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97fa31",
   "metadata": {},
   "source": [
    "# Let's find out the the hyperparameters for the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3acee",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd0044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [2, 4, 6, 8, 10],\n",
       "                         'min_samples_split': [3, 5, 7, 9, 11]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_decision_tree = tree.DecisionTreeClassifier()\n",
    "params = {\"max_depth\" : [2,4,6,8,10], \"min_samples_split\" : [3,5,7,9,11]}\n",
    "clf_decision_tree_CV = GridSearchCV(clf_decision_tree, params , cv = 10)\n",
    "clf_decision_tree_CV.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77777e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params are: {'max_depth': 2, 'min_samples_split': 3}\n",
      "best score is: 0.9427090349447764\n"
     ]
    }
   ],
   "source": [
    "print(f\"best params are: {clf_decision_tree_CV.best_params_}\")\n",
    "print(f\"best score is: {clf_decision_tree_CV.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe2a82",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ade1e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=25, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [3, 5, 7, 9, 11, 13, 15]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier()\n",
    "params = {\"n_neighbors\" : [3,5,7,9,11,13,15]}\n",
    "clf_knn_CV = GridSearchCV(clf_knn, params, cv = 25)\n",
    "clf_knn_CV.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fb42ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params are: {'n_neighbors': 3}\n",
      "best score is: 0.8837391108102008\n"
     ]
    }
   ],
   "source": [
    "print(f\"best params are: {clf_knn_CV.best_params_}\")\n",
    "print(f\"best score is: {clf_knn_CV.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92361354",
   "metadata": {},
   "source": [
    "### RandomForest\n",
    "\n",
    "referenced from this link:\n",
    "<u> https://www.kaggle.com/funxexcel/p2-random-forest-tuning-gridsearchcv </u> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0344da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,4]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24f80e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the param grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7820fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 320 candidates, totalling 3200 fits\n",
      "{'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 33}\n"
     ]
    }
   ],
   "source": [
    "rf_Model = RandomForestClassifier()\n",
    "\n",
    "rf_Grid = GridSearchCV(estimator = rf_Model, param_grid = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
    "\n",
    "rf_Grid.fit(X, y)\n",
    "\n",
    "print(rf_Grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a0563",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "689eeb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 5 candidates, totalling 75 fits\n",
      "Train Accuracy : 0.691\n",
      "Test Accuracy : 0.701\n",
      "Best Accuracy Through Grid Search : 0.692\n",
      "Best Parameters :  {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],}\n",
    "\n",
    "multinomial_nb_grid = GridSearchCV(MultinomialNB(), param_grid=params, n_jobs = -1, cv = 15, verbose = 5)\n",
    "multinomial_nb_grid.fit(X,y)\n",
    "\n",
    "print('Train Accuracy : %.3f'%multinomial_nb_grid.best_estimator_.score(X_train, y_train))\n",
    "print('Test Accuracy : %.3f'%multinomial_nb_grid.best_estimator_.score(X_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%multinomial_nb_grid.best_score_)\n",
    "print('Best Parameters : ',multinomial_nb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba4aab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7326d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(Y_test, Y_preds):\n",
    "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
    "    plt.yticks(range(3), range(3))\n",
    "    plt.xticks(range(3), range(3))\n",
    "    plt.colorbar();\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            plt.text(i-0.2,j+0.1, str(conf_mat[j, i]), color='tab:red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7799eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAFdCAYAAADWsgw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjPUlEQVR4nO3de5xVdb3/8ddnz43LcBuHy3BREIgOWoAQplYaapL5C/udUjhHs/Oz6EJ5OZ6ft8rK4hzrVOYx9UThyV9ZxEk7kg9PHjXTNBXBvAGiJCgDCIzInbnt/fn9sZe4E5g9zJ6Ztb5r3k8f6zF7r732Wp+1hc98+Kzv+m5zd0REJF6ZuAMQERElYxGRRFAyFhFJACVjEZEEUDIWEUkAJWMRkQQojzsAEZFSlPU/yr11X0n78H1b73X3mW1tY2ZlwDJgg7ufZWY1wK+A0cA64Bx3fyPa9irgQiALXOTu9xaLQclYRILmrfuomnBOSftofPqm2nZsdjGwCugfPb8SeMDdrzOzK6PnV5jZRGA2cAwwHLjfzN7h7tm2dq42hYgEzsAypS3FjmA2EvgI8JOC1bOA26LHtwFnF6xf5O5N7r4WWANML3YMJWMRCZsBZqUtUGtmywqWuW87yg+Ay4Fcwbqh7r4JIPo5JFo/AlhfsF19tK5NalOISPjaUd0W0eDu0w66a7OzgC3uvtzMTmlPNAdZV3TeCSVjEZG2nQR81MzOBHoB/c3s58BmM6tz901mVgdsibavB0YVvH8ksLHYQdSmEJHwld6mOCR3v8rdR7r7aPIX5n7v7ucBS4ALos0uAO6KHi8BZptZlZmNAcYDS4udgipjEQmcdUaboiOuAxab2YXAq8AnANx9hZktBlYCrcC8YiMpAExTaIpIyDJ9h3nVseeXtI/Gpd9dfqiecXdRm0JEJAHUphCRsBlxtSk6lZKxiASu+EW4ECgZi0j4UlAZh38GIiIpoMpYRMKnNoWISNxiG2fcqZSMRSRsb04UFLjwf52UyMxmmtlqM1sTzUkqncjMbjWzLWb2fNyxpJWZjTKzB81slZmtMLOL446p23XxFJrdIRlRxCSauf8m4MPARGBONDG0dJ6fAm1+g4KUrBW4zN3/BngvME9/jsPTo5Mx+Qmf17j7y+7eDCwiPzG0dBJ3fxjYFnccaebum9z9qejxLvLfRlF0/tz06PrJ5btDT+8ZH2wS6ONjikWkZGY2GpgCPBFzKN0rE37PuKcn4w5NAi2SRGZWDdwBXOLuO+OOp9uk5Hbo8M+gNB2aBFokacysgnwivt3d74w7Hjl8PT0ZPwmMN7MxZlZJfuLoJTHHJHJYzMyAhcAqd/9+3PHEogsnl+8uPToZu3sr8EXgXvIXPRa7+4p4o0oXM/sl8Bgwwczqo4m4pXOdBJwPzDCzp6PlzLiD6j66gJcK7n4PcE/ccaSVu8+JO4a0c/dHOPj1j54jIdVtKZLxK0FEpIfr8ZWxiKRAQloNpVAyFpGwJegiXCmUjEUkfCmojMM/g05gZnPjjiHt9Bl3D33O4VIyztMf4K6nz7h79MzPOQXjjNWmEJHAaXL5Q7KK3m5VA7pi112jsj+Z6mFBzUlx9FFD4w7hsNTWjWDcMZOC+owBqqvCqldGjjqSycdNDeZzXv/qK7ze0FB6aZqQ6rYUXZOMqwZQdewnu2LXEvnOjy6NO4Qe4eSxg+MOIdVO/YAmSXxTWL/2RUTeLiWztikZi0jg1DMWEUkG9YxFRBIgBZVx+GcgIpICqoxFJHxqU4iIxMzScQEv/DMQEeni26HNrJeZLTWzZ8xshZl9I1r/dTPbcLBvWDGzq8xsjZmtNrMzih1DlbGISHFNwAx33x19+esjZvbf0WvXu/t3Czc2s4nkv1PzGGA4cL+ZvcPds4c6gCpjEQmemZW0FON5u6OnFdHS1m3ns4BF7t7k7muBNcD0to6hZCwiQTM6JRnXmtmyguWA2e/MrMzMnga2APe5+xPRS180s2fN7FYzGxStGwGsL3h7fbTukJSMRSRs1gkLNLj7tIJlwdsP4+5Zd58MjASmm9mxwC3AWGAysAn4XkFUB+yirdNQMhYROQzuvh34AzDT3TdHSToH/Ji3WhH1wKiCt40ENra1XyVjEQlcaS2K9vSMzWywmQ2MHvcGTgNeMLO6gs0+BjwfPV4CzDazKjMbA4wHlrZ1DI2mEJHgtSehlqgOuM3MysgXsYvd/W4z+5mZTSbfglgHfBbA3VeY2WJgJdAKzGtrJAUoGYtICnR1Mnb3Z4EpB1l/fhvvmQ/Mb+8x1KYQEUkAVcYiErxuaFN0OSVjEQnbW8PTgqZkLCJBM9o3IiLplIxFJHhpSMa6gCcikgCqjEUkeGmojJWMRSR4SsYiInFLyWgK9YxFRBJAlbGIBE9tChGRmGmcsYhIQqQhGatnLCKSAKqMRSR84RfGSsYiEjhLR5tCyVhEgpeGZKyesYhIAqgyFpHgpaEyVjIWkaBpnLGISFKEn4uVjEUkcCkZTaELeCIiCaDKWESC12MqYzObaWarzWyNmV3Z1UGJiBwOMytpSYKiydjMyoCbgA8DE4E5ZjaxqwMTEWk3K3FJgPZUxtOBNe7+srs3A4uAWV0blohIz9KenvEIYH3B83rg+LdvZGZzgbkAVPbvjNhERNolKa2GUrQnGR/sLP2AFe4LgAUAmephB7wuItIVktT3LUV7knE9MKrg+UhgY9eEc/gqPctPdv+JSs9RRo4HKobz770nMD67gy/vfY7e3sqmTB++3HcKe6yC41u2clHjKso9R6tl+EGviTxZURv3aSRe3S3fofqpx2ntP5C137sVgMG/upXqZX8CM1oHDGTT56+gtSb/WVa98heG/fh6yvbtwS3Dun++Ba+sjPMUEi/72mvs/NrV5F5vgEyG3h/7OH3mnEfLi6vZ9S/X4nv3UjZ8BP2/eR2Z6uq4w02UnpKMnwTGm9kYYAMwG/i7Lo3qMDST4bPVJ7DPyin3HAt3P8qjrUO4fN9zXN97Ik+V1zKr6VU+2fgXbun9TrZbJRf3nU5Dphdjszu5afcTzBxwetynkXjbTz6DN844m7qbrtu/7vX/dS5bz/0/AAz67zupveNnvPaZSyGbZfgP/4WN866iafRYynbtwMvL4go9HOVlVF/6T1S8cyK5PXt44/xzqTz+BHZ962tUX3wZlVPfw767fsPen/0H1Z//UtzRSicregHP3VuBLwL3AquAxe6+oqsDazcz9ln+d0o5OcrJ4cBR2T08VXYEAI9XDObUlk0ArC4fQEOmFwB/yfSjkiwVno0l9JDsmziJbPVfXwvI9em7/3GmsXF/Q6vvs0/SdOTRNI0eC0C23wDIKBkXU1Y7mIp35gcqZfr2pWz0GHJbNpN9ZR0Vx00DoPL4E2j6/f1xhplIaRja1q6bPtz9HuCeLo6lwzLu3L7rYUbl9rC4ajTPlw/iL2X9OLl1Mw9VDOO05o0Mze074H2ntmxiddkAWkyJoqMGL1rIgIf/h2zvvrz6te8DULmxHgxGzb+c8p3b2XHiDLbNmh1zpGHJbtxA6+oXKD/23ZSNHUfzQw9SdcoMmu6/l9zm1+IOL3mSkU9LkorboXNmzOl/MjP7n84x2e2Mze7kG30mcU7TWm7f9TB9aaXF/vpUj87u4qLGVczv/e6Yok6HrbMvZM3Nv2Ln+05j0O/+CwDLZen9wvNs/NKXWXftv9HvyUfo89xT8QYakNzevey4/FKqL7uCTHU1/a+5lr3/uYht552D790LFRVxh5g4XV0Zm1kvM1tqZs+Y2Qoz+0a0vsbM7jOzl6Kfgwrec1V0o9xqMzuj2DFSkYzftDtTwfLyIzixZSvryvoxr/oE/r7fB/hdxQjqM2/9k3pIbh/f2/Mk1/SZQn1Z3zb2KO21430z6PfEwwC01gxm78RJZPsPwKt6sWfK8fRa+2LMEYbBW1vYefml9Jr5EXrNOA2A8tFHM+imBdT8fDFVZ3yYshGjiuxFukATMMPdJwGTgZlm9l7gSuABdx8PPBA9J7oxbjZwDDATuDm6ge6Qgk/GA3NNVOdaAKjyLMe3NLCurJpBuSYAzJ1PN77EHZVHAVCda+Hfdi/lxl7v5JnymtjiToOKTfX7H/db9ieaRxwJwO5J76HXK3/Bmhohm6XPymdoHjk6pijD4e7suvZrlI05mj7nXbB/fW7b6/nXczn2LlxA7789J64Qk8m6vjL2vN3R04pocfI3wN0Wrb8NODt6PAtY5O5N7r4WWEP+BrpDCn6ioMHexDf2/pkydwy4r3I4f6wYypymlzmnaR0Av6+o467KfDVxbvNaRuX28JnGl/hM40sAfKH6vbyRqYrpDMIw/IZv0nflM5Tt2sG4z5/D1k98iuo/P0HlxvWQydBSOyQ/kgLIVffj9bM+wZirP49j7JlyPLuPe2/MZ5B8Lc/8mcZ7fkvZuPFs+7uPA9D3CxeRXf8q+/5zEQBVHzyVXh89O8Yok8eATrgGV2tmywqeL4junXjrOPnKdjkwDrjJ3Z8ws6HuvgnA3TeZ2ZBo8xHA4wVvr4/WHVLwyfilsv78Xb+TD1j/y6qj+WXV0QesX9jrHSzs9Y7uCC1VNl781QPW7Zhx5iG33/n+09n5fg0ZPByVk49jyLLnDvpanznndXM0IemUEREN7j6trQ3cPQtMNrOBwG/M7Ng2gzrILtraf/BtChERs9KWw+Hu24E/kO8FbzazunwMVgdsiTY77JvllIxFRIows8FRRYyZ9QZOA14AlgBvNvgvAO6KHi8BZptZVXTD3HhgaVvHCL5NISLSDTdu1AG3RX3jDPmb3+42s8eAxWZ2IfAq8AkAd19hZouBlUArMC9qcxySkrGIhK0DrYbD5e7PAlMOsv514NRDvGc+ML+9x1AyFpGgGZDJhH8LnnrGIiIJoMpYRIKXkLl+SqJkLCLBS8rMa6VQMhaRsHXDBbzuoJ6xiEgCqDIWkaDl56YIvzRWMhaRwCXn2zpKoWQsIsFLQS5Wz1hEJAlUGYtI8NSmEBGJW0qGtikZi0jQNJpCRCQhUpCLdQFPRCQJVBmLSPDUphARSYAU5GIlYxEJnKWjMlbPWEQkAVQZi0jQ8kPb4o6idErGIhI4TRQkIpIIKcjF6hmLiCSBKmMRCZ7aFCIicdNEQSIi8UvLREHqGYuIJIAqYxEJXhoqYyVjEQleCnJx1yTjKRNG8ugj3+mKXUtkwmW/jTuEHuELZ0+MO4RUa9jT3Cn7UWUsIhK3lIym0AU8EZEEUGUsIkGzlMxNocpYRIJnVtpSfP82ysweNLNVZrbCzC6O1n/dzDaY2dPRcmbBe64yszVmttrMzih2DFXGIhK8TNdXxq3AZe7+lJn1A5ab2X3Ra9e7+3cLNzazicBs4BhgOHC/mb3D3bOHOoAqYxGRItx9k7s/FT3eBawCRrTxllnAIndvcve1wBpgelvHUDIWkeB1dZvir49lo4EpwBPRqi+a2bNmdquZDYrWjQDWF7ytnraTt5KxiITNou/AK2UBas1sWcEy9+DHsmrgDuASd98J3AKMBSYDm4DvvbnpQd7ubZ2HesYiErxM6S3jBnef1tYGZlZBPhHf7u53Arj75oLXfwzcHT2tB0YVvH0ksLGt/asyFhEpwvLl80Jglbt/v2B9XcFmHwOejx4vAWabWZWZjQHGA0vbOoYqYxEJXjeMMz4JOB94zsyejtZdDcwxs8nkWxDrgM8CuPsKM1sMrCQ/EmNeWyMpQMlYRFKgq3Oxuz/CwfvA97TxnvnA/PYeQ8lYRIJm5O/CC516xiIiCaDKWESC1wmjKWKnZCwiYbN0TBSkZCwiwUtBLlYyFpGwGd0yUVCX0wU8EZEEUGUsIsFLQWGsZCwi4dMFPBGRmHVkGswkUs9YRCQBVBmLSPDSMJpCyVhEghd+KlYyFpEUSMMFPPWMRUQSQJWxiAQtfwde3FGUTslYRMKmiYJERJIhBblYPWMRkSRQZSwiwVObQkQkZrqAJyKSEKqMRUQSIPxUrAt4IiKJoMpYRIJmpomCREQSIQW5WMlYRMKXhgt46hmLiCSAKmMRCV4KCuPilbGZ3WpmW8zs+e4ISETkcBhGxkpbkqA9bYqfAjO7OA4RkY6xt76UtKNLEhRNxu7+MLCtG2IREemxOq1nbGZzgbkAo448srN2KyJSlEZTFHD3Be4+zd2nDa4d3Fm7FREpKlPiUoyZjTKzB81slZmtMLOLo/U1Znafmb0U/RxU8J6rzGyNma02szOKHSMVoymyO3fS8LWv0rLmJcCo/ea36DV5StxhpUZFtoXvLv13KnKtlHmOPw57Fz8f9yGqm/dy9bO3M3TfNjb3ruGfJ/09uyv6UJ5r5aIVdzJ+Zz2O8e9/81GerRkb92kk3uT/9wOGPvckTf0G8IdrbgZg6k++TfXmegAq9u6hpU9fHvryjYxY+iDj7rtz/3v7b1jHQ1fdwM5RR8cSe5yMbqmMW4HL3P0pM+sHLDez+4BPAQ+4+3VmdiVwJXCFmU0EZgPHAMOB+83sHe6ePdQBUpGMt133z/Q56X30u/4GvKWZ3L7GuENKlZZMOVe8Zy6N5VWU5bJ8b+nNLKudwEmbn+fpmnEsPvqDnPPyg5zz8h+4dcKZfLh+KQCfP+kfGdC0m289tZCL3vsl3DSsvS2vnnAaa085iyk//f7+dcs/fcX+x8f8+ie09O4LwIbpH2TD9A8C0G/DOqbf8s0emYi7i7tvAjZFj3eZ2SpgBDALOCXa7DbgD8AV0fpF7t4ErDWzNcB04LFDHaM9Q9t+Ge1ggpnVm9mFHT2hrpDbvZvG5cuo/tuPA2AVlZT17x9zVCljRmN5FQDlnqU8l8UxTtiygvtHTAXg/hFTOXFLfvTjkbs38/QR4wDYUVXN7vLejN9RH0/sAdk2/lia+/Y7+IvuDH/qETa85wMHvDTiyYfY8J6Tuzi6ZMtYacvhMLPRwBTgCWBolKjfTNhDos1GAOsL3lYfrTukopWxu885vFC7V0v9ejKDamj4ytU0r15N5cSJHHHl1WT69Ik7tFTJeI4bH7uB4Xtf57ejTmT1wCMZ2LybbVX5X3zbqvozoHkPAC/3q+OELSv4w7BJDG7cwfid9Qxu3MGLcZ5A4GrWrKCp30D2DDnw7/OI5X9k6ee+EkNUydEJk8vXmtmygucL3H3B2zcys2rgDuASd9/ZRnvkYC94WwGE/+/G1izNq1bS79zZjPj1nWR692HHwh/HHVXq5CzDvBMv5byTv8yEHa9y1K7XDrntvSPew9ZeA7jx8X/jcy8sYeXAo8hmwv+jFqeRTz500Kp44NrVZCur2DVidPcHlRD5scJW0gI0vDkAIVoOlogryCfi2939zYb9ZjOri16vA7ZE6+uBUQVvHwlsbOs8gv8bUjZsKOVDh9Lr3ZMA6PuhD9G0cmXMUaXXnorePFszlmkNq9leWU1N004Aapp2sqMy38/MZcpY8M6PMu/ES/nGcZ+iurWRjX1q4ww7aJbNUvf0Y2yYepAWxbKH2TCtZ7cooOvbFJbP2AuBVe7+/YKXlgAXRI8vAO4qWD/bzKrMbAwwHlja5jkc3iknT3ntYMqG1dG8di0A+x5/nMqx42KOKl0GNO+mb8s+ACqzLUx5/SXW9x3M40MmctqG5QCctmE5jw05BoCqbDNVrc0ATGl4kaxleLV6aDzBp0DtC0+za9hIGge97RdaLpfvI087MElLpzsJOB+YYWZPR8uZwHXA6Wb2EnB69Bx3XwEsBlYCvwPmtTWSAlIymuKIq7/M1iv+L97SQsWoUdR+c37cIaVKTdMuLnvuV5R5DsN5eOi7WTpkIqsGHsXVz9zOGRuWsqXXIOZPOg+Agc27mb/sJ+Qsw+tV/fnXd82O+QzCcNzC71D74nNU7t7J6VddwOqz/p5XT/pQVP0emHCPWPM8+wbWsnfwsBiiTZauHtnm7o9w6G93OvUQ75kPtDsZmXubPeUOmTp1mj/6xLLiG0qHTbjst3GH0CN84eyJcYeQajd+7mzqVz9XUiqtG3+sX3DDncU3bMO3PzJhubtPK2knJUpFZSwiPVvw/VbScQ4iIsFTZSwiwUvBPEFKxiISNkvQBPGlUDIWkeClIBerZywikgSqjEUkeJ0wN0XslIxFJGgG6hmLiCRBCnKxesYiIkmgylhEwtaBCeKTSMlYRIJnh5zDJxxKxiIStPwFvLijKJ2SsYgELw3JWBfwREQSQJWxiASvjS8GDYaSsYgETT1jEZEkMN30ISIinUSVsYgET3NTiIjETD1jEZGESEFhrJ6xiEgSqDIWkcAZGc1NISISLyMdbQolYxEJW0qm0FTPWEQkAVQZi0jwNM5YRCRm6hmLiCSEKmMRkQRIQS7WBTwRkSRQZSwiQTPSUVV2STJ2oDWb64pdS+T2ee+LO4Qe4fRzvxp3CKnWtH5z6Tuxrv+mDzO7FTgL2OLux0brvg58BtgabXa1u98TvXYVcCGQBS5y93uLHSMNv1BEpIezEpd2+Ckw8yDrr3f3ydHyZiKeCMwGjonec7OZlRU7gJKxiEgR7v4wsK2dm88CFrl7k7uvBdYA04u9SclYRIKWn8/YSlqAWjNbVrDMbefhv2hmz5rZrWY2KFo3AlhfsE19tK5NSsYiErxOaFM0uPu0gmVBOw57CzAWmAxsAr5XEM7bebGdaTSFiAQvjnHG7r7/6qOZ/Ri4O3paD4wq2HQksLHY/lQZi4h0gJnVFTz9GPB89HgJMNvMqsxsDDAeWFpsf6qMRSRw1h1D234JnEK+t1wPfA04xcwmk29BrAM+C+DuK8xsMbASaAXmuXu22DGUjEUkaN1x04e7zznI6oVtbD8fmH84x1AyFpHgdXVl3B3UMxYRSQBVxiISvPDrYiVjEQldN8xN0R2UjEUkaJq1TUQkIdJQGafhF4qISPBUGYtI8MKvi5WMRSQFUtClUDIWkbDlL+CFn43VMxYRSQBVxiISPLUpRERiZ1gK2hRKxiISvDRUxuoZi4gkgCpjEQlaWkZTKBmLSNgsHW0KJWMRCV4akrF6xiIiCaDKWESCp6FtIiIxMyATfi5WMhaR8KkyFhFJAF3AExGRTqHKWESCpzaFiEjMdAFPRCQR0jFrm3rGIiIJoMpYRMKmuSlERJIhBblYyVhEwpa/gBd+OlbPWEQkAVQZi0jwwq+LVRmLSBpYiUux3ZvdamZbzOz5gnU1Znafmb0U/RxU8NpVZrbGzFab2RntOYWiydjMRpnZg2a2ysxWmNnF7dmxiEh3sRL/a4efAjPftu5K4AF3Hw88ED3HzCYCs4FjovfcbGZlxQ7Qnsq4FbjM3f8GeC8wLzqYiEiP4O4PA9vetnoWcFv0+Dbg7IL1i9y9yd3XAmuA6cWOUTQZu/smd38qerwLWAWMaM8JiIh0B7PSFqDWzJYVLHPbcdih7r4J8nkSGBKtHwGsL9iunnbkzMO6gGdmo4EpwBMHeW0uMBdg1KgjD2e3IiIl6YQLeA3uPq303QAHD8eLvandydjMqoE7gEvcfecBR3JfACwAOG7qtKIH7izbrvkK+x5+iExNDXV33gXAjltuYs8dvyZTk++nD/jSJfR+/we6K6RU6nvDfCqXPUpuwCB2/PB2AGzXTqq/81XKtmwiO6SO3Vd8E6/uDy0t9L3525SveQEsw57PXELru46L+QzCkHHn501L2WpVXFw1mf7ewnXNzzPc97HRenNF5bHssor92w/LNfLrpsf5UfkYflZxVIyRxyye4RSbzazO3TeZWR2wJVpfD4wq2G4ksLHYzto1msLMKsgn4tvd/c7DDLhL9Zl1NoNv+dEB66vP/yTDFt/JsMV3KhF3gqZTz2Tn16//q3W9f/0zWiZNZfuPFtMyaSq9f/0zAKr+ZwkAO278OTuv/QF9b70RcrlujzlEc1rXszbTd//zf2hdx9LMIM7udSJLM4P4h9ZX/mr7y1pe5NHMEd0dZqLkB0R0+QW8g1kCXBA9vgC4q2D9bDOrMrMxwHhgabGdtWc0hQELgVXu/v0OhdyFek2dRqb/gLjDSL3WY6fkq94ClUv/SNOMMwFomnEmlU/8EYDy9WtpeXf+X3w+sAbvW52vkqVNQ7yR9+ca+K+y4fvXnZxt4O7yOgDuLq/jlOzW/a+dkt3KhkxvXi5I3tI1zOyXwGPABDOrN7MLgeuA083sJeD06DnuvgJYDKwEfgfMc/dssWO0pzI+CTgfmGFmT0fLmR06o260e9EveO3jH2PbNV8ht3NH3OGkkm3fhtfUAuA1tdj2NwBoHT0un5izrWRe20jZX1aTadgcZ6hB+KfmF7mhYhy5gkrtCG+mwaoAaLAqarwZgF6e5VMt6/hR+ZhYYk2UEi/etedOanef4+517l7h7iPdfaG7v+7up7r7+OjntoLt57v7WHef4O7/3Z7TKNozdvdHCOwGl+pzzqX/3M+BGTtuupHt3/1Xaq79Vtxh9RhNp59FWf0rDPjHC8kNHkrrO9+FZ4oOs+zR3p9tYJtVsirTn6nZN4pu/7nWl7m9/Ej2mW6ihcAS1CGk8v9k2RG1+x9X/++Ps/VLX4gxmvTygTXYtoZ8VbytAR8Y3YBUVs7eT791b1D/y+eSGz7qEHsRgEm57ZycbeB9jY9S6Tn60sq3mlfwulVS6000WBW13sQ2qwTgXbkdnOZbuLh1Df28lRzQbBl+Vd5DP+cUZONUJuPs1q2UDR4MwL7f30/FuPExR5ROzdPfR9Xv76Hx45+k6vf30Dz9/fkXmhrBHXr1puLPSyFTRvZI/XO6LT+sGMcPK8YBMDX7Bp9sfYWvVB7DJS0vcVbrJn5aMZqzWjfxUFm+0Liw6q1RWJ9teZm9lPXcRJwSwSfj16/4JxqXPUlu+3Y2nj6D/p+fR9OyJ2lZ/QKYUTZ8ODVf/XrcYQav+l+voeL5P2M7tzPwH2axb86n2fe359PvO1+h1313kxs8lF1XzAcgs/0N+n/9UtyM3BGD2f2P18Qcfbj+o3w0325+jrMbN/Ka9eLyynfFHVICpeNrl8y984cEHzd1mj/8p6IjOaQET7+ii5Ld4fRzvxp3CKnWtHoxub1bSsqkE999nP/i7odKimPKUf2Xd+JNHx0SfGUsIj1bOydeSzxNoSkikgCqjEUkfCkojZWMRSR4abiAp2QsIsFLwfeRqmcsIpIEqoxFJHgpKIyVjEUkcCkZ26ZkLCLB0wU8EZGYGbqAJyIinUSVsYgELwWFsZKxiKRACrKxkrGIBC8NF/DUMxYRSQBVxiISvDSMplAyFpHgpSAXKxmLSAqkIBurZywikgCqjEUkaPmpKcIvjZWMRSRspgt4IiKJkIJcrJ6xiEgSqDIWkfCloDRWMhaRwJku4ImIJIEu4ImIxCwl37qkC3giIkmgylhEwtcNpbGZrQN2AVmg1d2nmVkN8CtgNLAOOMfd3+jI/lUZi0jwrMT/DsMH3X2yu0+Lnl8JPODu44EHoucdomQsIsEzK20pwSzgtujxbcDZHd2RkrGICNSa2bKCZe5BtnHgf8xsecHrQ919E0D0c0hHA1DPWESC1wkt44aC1sOhnOTuG81sCHCfmb1Q+mHfospYRMJWYouivW0Kd98Y/dwC/AaYDmw2szqA6OeWjp5Gl1TGf35qeUO/XmWvdMW+u0gt0BB3ECmnz7h7hPY5H9U5u+na4RRm1hfIuPuu6PGHgGuBJcAFwHXRz7s6eowuScbuPrgr9ttVzGxZO/6JIiXQZ9w99Dl3maHAbyxfRpcDv3D335nZk8BiM7sQeBX4REcPoJ6xiATN6Prbod39ZWDSQda/DpzaGcdQMhaR4KXhdmgl47wFcQfQA+gz7h498nNOw0RBGk0BuHuP/APcnfQZdw99zuFSZSwiwdN8xiIiSRB+LlYyFpHwpSAXKxmLSNg6YbKfRNAFPBGRBFBlLCLB0wU8EZEkCD8XKxmLSPhSkIvVMxYRSQJVxiISvDSMplAyFpHAHfaXiiaSkrGIBK07ptDsDuoZi4gkgJKxiEgCqE0hIsFLQ5tCyVhEgpeGC3hqU4iIJIAqYxEJW0pmbVMyFpGgGem4HVrJWETCl4JsrGQsIsHTBTwREekUqoxFJHi6gCcikgApyMVKxiKSAinIxuoZi4gkgCpjEQleGkZTKBmLSNDSMp+xuXvcMYiIdJiZ/Q6oLXE3De4+szPi6SglYxGRBNAFPBGRBFAyFhFJACVjEZEEUDIWEUkAJWMRkQT4/wnkQph1oGlfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, multinomial_nb_grid.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020cdb6f",
   "metadata": {},
   "source": [
    "## Now let's redo the process with the right hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab2e47e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix of RandomForest :\n",
      "[[557   0   0]\n",
      " [  7 485   0]\n",
      " [ 27  22 479]]\n",
      "\n",
      "confusion_matrix of DecisionTree :\n",
      "[[557   0   0]\n",
      " [  6 486   0]\n",
      " [ 24  25 479]]\n",
      "\n",
      "confusion_matrix of KNN :\n",
      "[[514  41   2]\n",
      " [ 26 441  25]\n",
      " [ 23  47 458]]\n",
      "\n",
      "confusion_matrix of Naive Bayes :\n",
      "[[395 138  24]\n",
      " [  6 309 177]\n",
      " [ 15 106 407]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_24c57_row0_col1,#T_24c57_row1_col0,#T_24c57_row1_col2,#T_24c57_row1_col3,#T_24c57_row1_col4{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_24c57_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >accuracy_on_test</th>        <th class=\"col_heading level0 col1\" >accuracy_on_train</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >f1</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_24c57_level0_row0\" class=\"row_heading level0 row0\" >RandomForest</th>\n",
       "                        <td id=\"T_24c57_row0_col0\" class=\"data row0 col0\" >0.964</td>\n",
       "                        <td id=\"T_24c57_row0_col1\" class=\"data row0 col1\" >0.965</td>\n",
       "                        <td id=\"T_24c57_row0_col2\" class=\"data row0 col2\" >0.966</td>\n",
       "                        <td id=\"T_24c57_row0_col3\" class=\"data row0 col3\" >0.964</td>\n",
       "                        <td id=\"T_24c57_row0_col4\" class=\"data row0 col4\" >0.964</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_24c57_level0_row1\" class=\"row_heading level0 row1\" >DecisionTree</th>\n",
       "                        <td id=\"T_24c57_row1_col0\" class=\"data row1 col0\" >0.965</td>\n",
       "                        <td id=\"T_24c57_row1_col1\" class=\"data row1 col1\" >0.964</td>\n",
       "                        <td id=\"T_24c57_row1_col2\" class=\"data row1 col2\" >0.967</td>\n",
       "                        <td id=\"T_24c57_row1_col3\" class=\"data row1 col3\" >0.965</td>\n",
       "                        <td id=\"T_24c57_row1_col4\" class=\"data row1 col4\" >0.965</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_24c57_level0_row2\" class=\"row_heading level0 row2\" >KNN</th>\n",
       "                        <td id=\"T_24c57_row2_col0\" class=\"data row2 col0\" >0.896</td>\n",
       "                        <td id=\"T_24c57_row2_col1\" class=\"data row2 col1\" >0.941</td>\n",
       "                        <td id=\"T_24c57_row2_col2\" class=\"data row2 col2\" >0.897</td>\n",
       "                        <td id=\"T_24c57_row2_col3\" class=\"data row2 col3\" >0.896</td>\n",
       "                        <td id=\"T_24c57_row2_col4\" class=\"data row2 col4\" >0.895</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_24c57_level0_row3\" class=\"row_heading level0 row3\" >Naive Bayes</th>\n",
       "                        <td id=\"T_24c57_row3_col0\" class=\"data row3 col0\" >0.705</td>\n",
       "                        <td id=\"T_24c57_row3_col1\" class=\"data row3 col1\" >0.692</td>\n",
       "                        <td id=\"T_24c57_row3_col2\" class=\"data row3 col2\" >0.726</td>\n",
       "                        <td id=\"T_24c57_row3_col3\" class=\"data row3 col3\" >0.703</td>\n",
       "                        <td id=\"T_24c57_row3_col4\" class=\"data row3 col4\" >0.707</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2706aa68040>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_samples.drop('book_genre', axis = 1)\n",
    "y = df_samples['book_genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "ml_models = {\n",
    "    'RandomForest'      : RandomForestClassifier(bootstrap = True, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 33),   \n",
    "    'DecisionTree'      : DecisionTreeClassifier(max_depth= 2, min_samples_split=3),   \n",
    "    'KNN'               : KNeighborsClassifier(n_neighbors =  3), \n",
    "    'Naive Bayes'       : MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), \n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame([])\n",
    "\n",
    "for model_name in ml_models:\n",
    "    \n",
    "    metrics = {}\n",
    "\n",
    "    clf_model = ml_models[model_name].fit(X_train, y_train)\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "    y_pred_train = clf_model.predict(X_train)\n",
    "    \n",
    "    \n",
    "    metrics['accuracy_on_test'] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    metrics['accuracy_on_train'] = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    metrics['precision'] = precision_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    metrics['recall'] = recall_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    metrics['f1'] = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    df_metrics = pd.concat([df_metrics,pd.DataFrame(metrics, index=[model_name]).T],axis=1)\n",
    "    \n",
    "    print(\"confusion_matrix of\", model_name, \":\")\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "df_metrics.T.style.highlight_max(color='lightgreen').set_precision(3)"
   ]
  },
  {
   "attachments": {
    "Screenshot%20%28135%29.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a68004d5",
   "metadata": {},
   "source": [
    "## when you have class imbalance \n",
    "\n",
    "### Micro average\n",
    "\n",
    "![Screenshot%20%28135%29.png](attachment:Screenshot%20%28135%29.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dda418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fiction_df = df_copy[df_copy[\"book_genre\"] == 1]\n",
    "sample_sport_df = df_copy[df_copy[\"book_genre\"] == 2]\n",
    "sample_mbs_df =  df_copy[df_copy[\"book_genre\"] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8624d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [sample_fiction_df, sample_sport_df, sample_mbs_df]\n",
    "\n",
    "df_samples = pd.concat(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb224969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix of RandomForest :\n",
      "[[719   0   0]\n",
      " [ 11 515   2]\n",
      " [ 19  26 576]]\n",
      "\n",
      "confusion_matrix of DecisionTree :\n",
      "[[719   0   0]\n",
      " [ 11 514   3]\n",
      " [ 18  28 575]]\n",
      "\n",
      "confusion_matrix of KNN :\n",
      "[[685  31   3]\n",
      " [ 39 442  47]\n",
      " [ 19  47 555]]\n",
      "\n",
      "confusion_matrix of Naive Bayes :\n",
      "[[522 150  47]\n",
      " [ 11 318 199]\n",
      " [ 14 140 467]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_095b4_row0_col0,#T_095b4_row0_col1,#T_095b4_row0_col2,#T_095b4_row0_col3,#T_095b4_row0_col4{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_095b4_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >accuracy_on_test</th>        <th class=\"col_heading level0 col1\" >accuracy_on_train</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >f1</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_095b4_level0_row0\" class=\"row_heading level0 row0\" >RandomForest</th>\n",
       "                        <td id=\"T_095b4_row0_col0\" class=\"data row0 col0\" >0.969</td>\n",
       "                        <td id=\"T_095b4_row0_col1\" class=\"data row0 col1\" >0.965</td>\n",
       "                        <td id=\"T_095b4_row0_col2\" class=\"data row0 col2\" >0.969</td>\n",
       "                        <td id=\"T_095b4_row0_col3\" class=\"data row0 col3\" >0.969</td>\n",
       "                        <td id=\"T_095b4_row0_col4\" class=\"data row0 col4\" >0.969</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_095b4_level0_row1\" class=\"row_heading level0 row1\" >DecisionTree</th>\n",
       "                        <td id=\"T_095b4_row1_col0\" class=\"data row1 col0\" >0.968</td>\n",
       "                        <td id=\"T_095b4_row1_col1\" class=\"data row1 col1\" >0.964</td>\n",
       "                        <td id=\"T_095b4_row1_col2\" class=\"data row1 col2\" >0.968</td>\n",
       "                        <td id=\"T_095b4_row1_col3\" class=\"data row1 col3\" >0.968</td>\n",
       "                        <td id=\"T_095b4_row1_col4\" class=\"data row1 col4\" >0.968</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_095b4_level0_row2\" class=\"row_heading level0 row2\" >KNN</th>\n",
       "                        <td id=\"T_095b4_row2_col0\" class=\"data row2 col0\" >0.900</td>\n",
       "                        <td id=\"T_095b4_row2_col1\" class=\"data row2 col1\" >0.948</td>\n",
       "                        <td id=\"T_095b4_row2_col2\" class=\"data row2 col2\" >0.900</td>\n",
       "                        <td id=\"T_095b4_row2_col3\" class=\"data row2 col3\" >0.900</td>\n",
       "                        <td id=\"T_095b4_row2_col4\" class=\"data row2 col4\" >0.900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_095b4_level0_row3\" class=\"row_heading level0 row3\" >Naive Bayes</th>\n",
       "                        <td id=\"T_095b4_row3_col0\" class=\"data row3 col0\" >0.700</td>\n",
       "                        <td id=\"T_095b4_row3_col1\" class=\"data row3 col1\" >0.701</td>\n",
       "                        <td id=\"T_095b4_row3_col2\" class=\"data row3 col2\" >0.700</td>\n",
       "                        <td id=\"T_095b4_row3_col3\" class=\"data row3 col3\" >0.700</td>\n",
       "                        <td id=\"T_095b4_row3_col4\" class=\"data row3 col4\" >0.700</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2707230ec10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_samples.drop('book_genre', axis = 1)\n",
    "y = df_samples['book_genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "ml_models = {\n",
    "    'RandomForest'      : RandomForestClassifier(bootstrap = True, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 33),   \n",
    "    'DecisionTree'      : DecisionTreeClassifier(max_depth= 2, min_samples_split=3),   \n",
    "    'KNN'               : KNeighborsClassifier(n_neighbors =  3), \n",
    "    'Naive Bayes'       : MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), \n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame([])\n",
    "\n",
    "for model_name in ml_models:\n",
    "    \n",
    "    metrics = {}\n",
    "\n",
    "    clf_model = ml_models[model_name].fit(X_train, y_train)\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "    y_pred_train = clf_model.predict(X_train)\n",
    "    \n",
    "    \n",
    "    metrics['accuracy_on_test'] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    metrics['accuracy_on_train'] = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    metrics['precision'] = precision_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    metrics['recall'] = recall_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    metrics['f1'] = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    df_metrics = pd.concat([df_metrics,pd.DataFrame(metrics, index=[model_name]).T],axis=1)\n",
    "    \n",
    "    print(\"confusion_matrix of\", model_name, \":\")\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "df_metrics.T.style.highlight_max(color='lightgreen').set_precision(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
